{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Maximum number of threads per block: 1024\n",
        "Maximum number of threads per SM: 2048\n",
        "Shared memory per SM: 64 KB\n",
        "Register file size per SM: 65536 registers\n",
        "\n",
        "Number of Streaming Multiprocessors (SMs): 40\n",
        "Maximum number of resident blocks per SM: 16\n",
        "'''"
      ],
      "metadata": {
        "id": "KGms-7RryfVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q52srwlpiyrs",
        "outputId": "9c851145-a776-408e-ef95-5cd6119e9f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 10000 samples to random_data_10000.csv\n",
            "Saved 100000 samples to random_data_100000.csv\n",
            "Saved 1000000 samples to random_data_1000000.csv\n",
            "Saved 10000000 samples to random_data_10000000.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# List of different sizes for the datasets\n",
        "sizes = [10000, 100000, 1000000, 10000000]\n",
        "num_features = 5\n",
        "\n",
        "# Loop through each size and generate, then save the data\n",
        "for size in sizes:\n",
        "    # Generate random data\n",
        "    data = pd.DataFrame(np.random.randn(size, num_features), columns=[f'feature_{i}' for i in range(num_features)])\n",
        "\n",
        "    # Save the data to a CSV file\n",
        "    filename = f'random_data_{size}.csv'\n",
        "    data.to_csv(filename, index=False)\n",
        "\n",
        "    print(f'Saved {size} samples to {filename}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jmIny3_zqoc",
        "outputId": "2ef05a72-d217-4473-e5a0-83e22047cc1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting kmeans_rnd.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile kmeans_rnd.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define TPB 32   // Threads per block\n",
        "#define MAX_ITER 10\n",
        "#define MAX_LINE_LENGTH 1024\n",
        "\n",
        "// Function to read CSV data\n",
        "int readCSVData(const char *filename, float **data, int *num_points, int *num_dims) {\n",
        "    FILE *file = fopen(filename, \"r\");\n",
        "    if (!file) {\n",
        "        perror(\"Unable to open file\");\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    char line[MAX_LINE_LENGTH];\n",
        "    int n = 0, d = 0;\n",
        "\n",
        "    // Read first line to determine the number of dimensions\n",
        "    if (fgets(line, MAX_LINE_LENGTH, file)) {\n",
        "        char *token = strtok(line, \",\");\n",
        "        while (token) {\n",
        "            d++;\n",
        "            token = strtok(NULL, \",\");\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Count number of points\n",
        "    while (fgets(line, MAX_LINE_LENGTH, file)) {\n",
        "        n++;\n",
        "    }\n",
        "\n",
        "    // Allocate memory for data\n",
        "    *data = (float *)malloc(n * d * sizeof(float));\n",
        "    if (!*data) {\n",
        "        perror(\"Unable to allocate memory\");\n",
        "        fclose(file);\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    rewind(file);\n",
        "\n",
        "    // Read data into the array\n",
        "    int point = 0;\n",
        "    while (fgets(line, MAX_LINE_LENGTH, file)) {\n",
        "        char *token = strtok(line, \",\");\n",
        "        int dim = 0;\n",
        "        while (token) {\n",
        "            (*data)[point * d + dim] = atof(token);\n",
        "            token = strtok(NULL, \",\");\n",
        "            dim++;\n",
        "        }\n",
        "        point++;\n",
        "    }\n",
        "\n",
        "    fclose(file);\n",
        "\n",
        "    *num_points = n;\n",
        "    *num_dims = d;\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "__device__ float distance(float *a, float *b, int dims) {\n",
        "    float dist = 0;\n",
        "    for (int i = 0; i < dims; ++i) {\n",
        "        dist += (a[i] - b[i]) * (a[i] - b[i]);\n",
        "    }\n",
        "    return sqrt(dist);\n",
        "}\n",
        "\n",
        "__global__ void kMeansClusterAssignment(float *d_datapoints, int *d_clust_assn, float *d_centroids, int N, int K, int D) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx >= N) return;\n",
        "\n",
        "    float min_dist = INFINITY;\n",
        "    int closest_centroid = 0;\n",
        "\n",
        "    for (int c = 0; c < K; ++c) {\n",
        "        float dist = distance(&d_datapoints[idx * D], &d_centroids[c * D], D);\n",
        "        if (dist < min_dist) {\n",
        "            min_dist = dist;\n",
        "            closest_centroid = c;\n",
        "        }\n",
        "    }\n",
        "    d_clust_assn[idx] = closest_centroid;\n",
        "}\n",
        "\n",
        "__global__ void kMeansCentroidUpdate(float *d_datapoints, int *d_clust_assn, float *d_centroids, int *d_clust_sizes, int N, int K, int D) {\n",
        "    extern __shared__ float s_centroids[];\n",
        "    int *s_counts = (int *)&s_centroids[K * D];\n",
        "\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int tid = threadIdx.x;\n",
        "\n",
        "    if (tid < K) {\n",
        "        for (int i = 0; i < D; ++i) {\n",
        "            s_centroids[tid * D + i] = 0;\n",
        "        }\n",
        "        s_counts[tid] = 0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    if (idx < N) {\n",
        "        int cluster_id = d_clust_assn[idx];\n",
        "        for (int i = 0; i < D; ++i) {\n",
        "            atomicAdd(&s_centroids[cluster_id * D + i], d_datapoints[idx * D + i]);\n",
        "        }\n",
        "        atomicAdd(&s_counts[cluster_id], 1);\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    if (tid < K) {\n",
        "        for (int i = 0; i < D; ++i) {\n",
        "            atomicAdd(&d_centroids[tid * D + i], s_centroids[tid * D + i]);\n",
        "        }\n",
        "        atomicAdd(&d_clust_sizes[tid], s_counts[tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void normalizeCentroids(float *d_centroids, int *d_clust_sizes, int K, int D) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx >= K) return;\n",
        "\n",
        "    for (int i = 0; i < D; ++i) {\n",
        "        if (d_clust_sizes[idx] > 0) {\n",
        "            d_centroids[idx * D + i] /= d_clust_sizes[idx];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    if (argc != 3) {\n",
        "        fprintf(stderr, \"Usage: %s <input.csv> <K>\\n\", argv[0]);\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    const char *filename = argv[1];\n",
        "    int K = atoi(argv[2]);\n",
        "\n",
        "    float *datapoints;\n",
        "    int num_points = 0;\n",
        "    int num_dims = 0;\n",
        "\n",
        "    if (readCSVData(filename, &datapoints, &num_points, &num_dims) != 0) {\n",
        "        fprintf(stderr, \"Error reading data from file\\n\");\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    float *d_datapoints, *d_centroids;\n",
        "    int *d_clust_assn, *d_clust_sizes;\n",
        "\n",
        "    cudaMalloc(&d_datapoints, num_points * num_dims * sizeof(float));\n",
        "    cudaMalloc(&d_clust_assn, num_points * sizeof(int));\n",
        "    cudaMalloc(&d_centroids, K * num_dims * sizeof(float));\n",
        "    cudaMalloc(&d_clust_sizes, K * sizeof(int));\n",
        "\n",
        "    float *h_centroids = (float *)malloc(K * num_dims * sizeof(float));\n",
        "    int *h_clust_sizes = (int *)malloc(K * sizeof(int));\n",
        "\n",
        "    srand(time(0));\n",
        "\n",
        "    for (int c = 0; c < K; ++c) {\n",
        "        for (int d = 0; d < num_dims; ++d) {\n",
        "            h_centroids[c * num_dims + d] = datapoints[c * num_dims + d];\n",
        "        }\n",
        "        h_clust_sizes[c] = 0;\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(d_centroids, h_centroids, K * num_dims * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_datapoints, datapoints, num_points * num_dims * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaEvent_t start_total, stop_total;\n",
        "    cudaEventCreate(&start_total);\n",
        "    cudaEventCreate(&stop_total);\n",
        "\n",
        "    cudaEventRecord(start_total);\n",
        "\n",
        "    for (int cur_iter = 0; cur_iter < MAX_ITER; ++cur_iter) {\n",
        "        kMeansClusterAssignment<<<(num_points + TPB - 1) / TPB, TPB>>>(d_datapoints, d_clust_assn, d_centroids, num_points, K, num_dims);\n",
        "\n",
        "        // Reset centroids and sizes on device\n",
        "        cudaMemset(d_centroids, 0, K * num_dims * sizeof(float));\n",
        "        cudaMemset(d_clust_sizes, 0, K * sizeof(int));\n",
        "\n",
        "        size_t shared_mem_size = K * num_dims * sizeof(float) + K * sizeof(int);\n",
        "        kMeansCentroidUpdate<<<(num_points + TPB - 1) / TPB, TPB, shared_mem_size>>>(d_datapoints, d_clust_assn, d_centroids, d_clust_sizes, num_points, K, num_dims);\n",
        "\n",
        "        normalizeCentroids<<<(K + TPB - 1) / TPB, TPB>>>(d_centroids, d_clust_sizes, K, num_dims);\n",
        "\n",
        "        cudaMemcpy(h_centroids, d_centroids, K * num_dims * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        /*printf(\"Iteration %d centroids:\\n\", cur_iter + 1);\n",
        "        for (int i = 0; i < K; ++i) {\n",
        "            printf(\"Centroid %d: \", i);\n",
        "            for (int j = 0; j < num_dims; ++j) {\n",
        "                printf(\"%f \", h_centroids[i * num_dims + j]);\n",
        "            }\n",
        "            printf(\"\\n\");\n",
        "        }*/\n",
        "    }\n",
        "\n",
        "    cudaEventRecord(stop_total);\n",
        "    cudaEventSynchronize(stop_total);\n",
        "\n",
        "    float total_milliseconds = 0;\n",
        "    cudaEventElapsedTime(&total_milliseconds, start_total, stop_total);\n",
        "    printf(\"Total time: %f milliseconds\\n\", total_milliseconds);\n",
        "\n",
        "    cudaFree(d_datapoints);\n",
        "    cudaFree(d_clust_assn);\n",
        "    cudaFree(d_centroids);\n",
        "    cudaFree(d_clust_sizes);\n",
        "\n",
        "    free(h_centroids);\n",
        "    free(datapoints);\n",
        "    free(h_clust_sizes);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5yt8D0zOjJu",
        "outputId": "0f884481-d389-41ef-b5ba-f6131351d90b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time for K-means clustering: 0.000000 milliseconds\n"
          ]
        }
      ],
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_10000.csv 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_10000.csv 100"
      ],
      "metadata": {
        "id": "MGzS10rk0kff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_10000.csv 1000"
      ],
      "metadata": {
        "id": "AadLOBG00lOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_100000.csv 10"
      ],
      "metadata": {
        "id": "n9TOpNu90mqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_100000.csv 100"
      ],
      "metadata": {
        "id": "4xoJPm9D0plN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_100000.csv 1000"
      ],
      "metadata": {
        "id": "1enDomKt0qeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_1000000.csv 10"
      ],
      "metadata": {
        "id": "HffUeXg50rT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_1000000.csv 100"
      ],
      "metadata": {
        "id": "DysNmjwp0sgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_1000000.csv 1000"
      ],
      "metadata": {
        "id": "pXyNCtsh0uFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_10000000.csv 10"
      ],
      "metadata": {
        "id": "SHt-_Rt30vJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_10000000.csv 100"
      ],
      "metadata": {
        "id": "_S4nYcWT0wvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_10000000.csv 1000"
      ],
      "metadata": {
        "id": "b7UkQQ180y3Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}