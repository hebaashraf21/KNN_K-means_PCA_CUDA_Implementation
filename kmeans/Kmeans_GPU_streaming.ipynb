{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Maximum number of threads per block: 1024\n",
        "Maximum number of threads per SM: 2048\n",
        "Shared memory per SM: 64 KB\n",
        "Register file size per SM: 65536 registers\n",
        "\n",
        "Number of Streaming Multiprocessors (SMs): 40\n",
        "Maximum number of resident blocks per SM: 16\n",
        "'''"
      ],
      "metadata": {
        "id": "KGms-7RryfVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q52srwlpiyrs",
        "outputId": "cad8f351-444c-4060-91be-ca21f391cd8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 10000 samples to random_data_10000.csv\n",
            "Saved 100000 samples to random_data_100000.csv\n",
            "Saved 1000000 samples to random_data_1000000.csv\n",
            "Saved 10000000 samples to random_data_10000000.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# List of different sizes for the datasets\n",
        "sizes = [10000, 100000, 1000000, 10000000]\n",
        "num_features = 5\n",
        "\n",
        "# Loop through each size and generate, then save the data\n",
        "for size in sizes:\n",
        "    # Generate random data\n",
        "    data = pd.DataFrame(np.random.randn(size, num_features), columns=[f'feature_{i}' for i in range(num_features)])\n",
        "\n",
        "    # Save the data to a CSV file\n",
        "    filename = f'random_data_{size}.csv'\n",
        "    data.to_csv(filename, index=False)\n",
        "\n",
        "    print(f'Saved {size} samples to {filename}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jmIny3_zqoc",
        "outputId": "8878e4fb-09d7-4bf8-8da0-c41b81c15621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing kmeans_GPU_streaming.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile kmeans_GPU_streaming.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define TPB 128   // Threads per block\n",
        "#define MAX_ITER 10\n",
        "#define MAX_LINE_LENGTH 1024\n",
        "\n",
        "// Function to read CSV data\n",
        "// Reads data from a CSV file.\n",
        "// Determines the number of points (num_points) and dimensions (num_dims).\n",
        "// Allocates memory for the data array.\n",
        "int readCSVData(const char *filename, float **data, int *num_points, int *num_dims) {\n",
        "    FILE *file = fopen(filename, \"r\");\n",
        "    if (!file) {\n",
        "        perror(\"Unable to open file\");\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    char line[MAX_LINE_LENGTH];\n",
        "    int n = 0, d = 0;\n",
        "\n",
        "    // Read first line to determine the number of dimensions\n",
        "    if (fgets(line, MAX_LINE_LENGTH, file)) {\n",
        "        char *token = strtok(line, \",\");\n",
        "        while (token) {\n",
        "            d++;\n",
        "            token = strtok(NULL, \",\");\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Count number of points\n",
        "    while (fgets(line, MAX_LINE_LENGTH, file)) {\n",
        "        n++;\n",
        "    }\n",
        "\n",
        "    // Allocate memory for data\n",
        "    *data = (float *)malloc(n * d * sizeof(float));\n",
        "    if (!*data) {\n",
        "        perror(\"Unable to allocate memory\");\n",
        "        fclose(file);\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    rewind(file);\n",
        "\n",
        "    // Read data into the array\n",
        "    int point = 0;\n",
        "    while (fgets(line, MAX_LINE_LENGTH, file)) {\n",
        "        char *token = strtok(line, \",\");\n",
        "        int dim = 0;\n",
        "        while (token) {\n",
        "            (*data)[point * d + dim] = atof(token);\n",
        "            token = strtok(NULL, \",\");\n",
        "            dim++;\n",
        "        }\n",
        "        point++;\n",
        "    }\n",
        "\n",
        "    fclose(file);\n",
        "\n",
        "    *num_points = n;\n",
        "    *num_dims = d;\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "// Computes the Euclidean distance between two points in dims dimensions.\n",
        "__device__ float distance(float *a, float *b, int dims) {\n",
        "    float dist = 0;\n",
        "    for (int i = 0; i < dims; ++i) {\n",
        "        dist += (a[i] - b[i]) * (a[i] - b[i]);\n",
        "    }\n",
        "    return sqrt(dist);\n",
        "}\n",
        "\n",
        "// Assigns each data point to the nearest centroid.\n",
        "__global__ void kMeansClusterAssignment(float *d_datapoints, int *d_clust_assn, float *d_centroids, int N, int K, int D) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx >= N) return;\n",
        "\n",
        "    float min_dist = INFINITY;\n",
        "    int closest_centroid = 0;\n",
        "\n",
        "    for (int c = 0; c < K; ++c) {\n",
        "        float dist = distance(&d_datapoints[idx * D], &d_centroids[c * D], D);\n",
        "        if (dist < min_dist) {\n",
        "            min_dist = dist;\n",
        "            closest_centroid = c;\n",
        "        }\n",
        "    }\n",
        "    d_clust_assn[idx] = closest_centroid;\n",
        "}\n",
        "\n",
        "// Updates centroids by averaging the assigned points.\n",
        "__global__ void kMeansCentroidUpdate(float *d_datapoints, int *d_clust_assn, float *d_centroids, int *d_clust_sizes, int N, int K, int D) {\n",
        "    // This declares shared memory for each block to hold partial centroid accumulators.\n",
        "    extern __shared__ float s_centroids[];\n",
        "    // to store the count of data points assigned to each centroid. (in the shared)\n",
        "    int *s_counts = (int *)&s_centroids[K * D];\n",
        "\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int tid = threadIdx.x;\n",
        "\n",
        "    // Each thread initializes its partial centroid accumulator (s_centroids) and cluster size counter (s_counts) to zero.\n",
        "    if (tid < K) {\n",
        "        for (int i = 0; i < D; ++i) {\n",
        "            s_centroids[tid * D + i] = 0;\n",
        "        }\n",
        "        s_counts[tid] = 0;\n",
        "    }\n",
        "    // to ensure proper initialization\n",
        "    __syncthreads();\n",
        "\n",
        "    // Centroid Accumulation\n",
        "    if (idx < N) {\n",
        "        int cluster_id = d_clust_assn[idx];\n",
        "        // The thread atomically accumulates the coordinates of the data point\n",
        "        // into the partial centroid accumulator (s_centroids) corresponding to its assigned cluster.\n",
        "        for (int i = 0; i < D; ++i) {\n",
        "            atomicAdd(&s_centroids[cluster_id * D + i], d_datapoints[idx * D + i]);\n",
        "        }\n",
        "\n",
        "        // increments the cluster size counter (s_counts) for the assigned cluster.\n",
        "        atomicAdd(&s_counts[cluster_id], 1);\n",
        "    }\n",
        "    // to ensure all partial accumulators and cluster size counters are updated\n",
        "    __syncthreads();\n",
        "\n",
        "    // Centroid Update:\n",
        "    if (tid < K) {\n",
        "        for (int i = 0; i < D; ++i) {\n",
        "          // Each thread atomically adds its partial centroid accumulator (s_centroids)\n",
        "          // to the corresponding centroid in the global centroids array.\n",
        "            atomicAdd(&d_centroids[tid * D + i], s_centroids[tid * D + i]);\n",
        "        }\n",
        "        // It also atomically adds its cluster size counter (s_counts)\n",
        "        // to the corresponding cluster size in the global cluster size array.\n",
        "        atomicAdd(&d_clust_sizes[tid], s_counts[tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Normalizes centroids by dividing the sum of points by the number of points in each cluster.\n",
        "__global__ void normalizeCentroids(float *d_centroids, int *d_clust_sizes, int K, int D) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx >= K) return;\n",
        "\n",
        "    for (int i = 0; i < D; ++i) {\n",
        "        if (d_clust_sizes[idx] > 0) {\n",
        "            d_centroids[idx * D + i] /= d_clust_sizes[idx];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    if (argc != 3) {\n",
        "        fprintf(stderr, \"Usage: %s <input.csv> <K>\\n\", argv[0]);\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    const char *filename = argv[1];\n",
        "    // number of clusters\n",
        "    int K = atoi(argv[2]);\n",
        "\n",
        "    float *datapoints;\n",
        "    int num_points = 0;\n",
        "    int num_dims = 0;\n",
        "\n",
        "    if (readCSVData(filename, &datapoints, &num_points, &num_dims) != 0) {\n",
        "        fprintf(stderr, \"Error reading data from file\\n\");\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    float *d_datapoints, *d_centroids;\n",
        "    int *d_clust_assn, *d_clust_sizes;\n",
        "\n",
        "    cudaMalloc(&d_datapoints, num_points * num_dims * sizeof(float));\n",
        "    cudaMalloc(&d_clust_assn, num_points * sizeof(int));\n",
        "    cudaMalloc(&d_centroids, K * num_dims * sizeof(float));\n",
        "    // keep track of the number of points assigned to each cluster.\n",
        "    cudaMalloc(&d_clust_sizes, K * sizeof(int));\n",
        "\n",
        "    float *h_centroids = (float *)malloc(K * num_dims * sizeof(float));\n",
        "    // keep track of the number of points assigned to each cluster.\n",
        "    int *h_clust_sizes = (int *)malloc(K * sizeof(int));\n",
        "\n",
        "    // Create CUDA streams\n",
        "    cudaStream_t streams[2];\n",
        "    cudaStreamCreate(&streams[0]); // Create the first stream\n",
        "    cudaStreamCreate(&streams[1]); // Create the second stream\n",
        "\n",
        "    srand(time(0));\n",
        "\n",
        "    // It copies the feature values from a data point to initialize the corresponding centroid.\n",
        "    for (int c = 0; c < K; ++c) {\n",
        "        for (int d = 0; d < num_dims; ++d) {\n",
        "            h_centroids[c * num_dims + d] = datapoints[c * num_dims + d];\n",
        "        }\n",
        "        h_clust_sizes[c] = 0;\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(d_centroids, h_centroids, K * num_dims * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_datapoints, datapoints, num_points * num_dims * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaEvent_t start_total, stop_total;\n",
        "    cudaEventCreate(&start_total);\n",
        "    cudaEventCreate(&stop_total);\n",
        "\n",
        "    cudaEventRecord(start_total);\n",
        "\n",
        "    for (int cur_iter = 0; cur_iter < MAX_ITER; ++cur_iter) {\n",
        "        // Launch KMeansClusterAssignment kernel\n",
        "        kMeansClusterAssignment<<<(num_points + TPB - 1) / TPB, TPB, 0, streams[0]>>>(d_datapoints, d_clust_assn, d_centroids, num_points, K, num_dims);\n",
        "\n",
        "        // Reset centroids and sizes on device\n",
        "        cudaMemsetAsync(d_centroids, 0, K * num_dims * sizeof(float), streams[0]);\n",
        "        cudaMemsetAsync(d_clust_sizes, 0, K * sizeof(int), streams[0]);\n",
        "\n",
        "        /*\n",
        "        K * num_dims * sizeof(float): This calculates the size of shared memory required to store\n",
        "        the accumulator for each centroid's dimensions.\n",
        "        K * sizeof(int): This calculates the size of shared memory required to store\n",
        "        the array holding the size of each cluster.\n",
        "        */\n",
        "        size_t shared_mem_size = K * num_dims * sizeof(float) + K * sizeof(int);\n",
        "        // Launch KMeansCentroidUpdate kernel with stream 1\n",
        "        kMeansCentroidUpdate<<<(num_points + TPB - 1) / TPB, TPB, shared_mem_size, streams[0]>>>(d_datapoints, d_clust_assn, d_centroids, d_clust_sizes, num_points, K, num_dims);\n",
        "\n",
        "        // Normalize centroids with stream 1\n",
        "        normalizeCentroids<<<(K + TPB - 1) / TPB, TPB, 0, streams[0]>>>(d_centroids, d_clust_sizes, K, num_dims);\n",
        "\n",
        "        cudaMemcpyAsync(h_centroids, d_centroids, K * num_dims * sizeof(float), cudaMemcpyDeviceToHost, streams[1]);\n",
        "\n",
        "        /*printf(\"Iteration %d centroids:\\n\", cur_iter + 1);\n",
        "        for (int i = 0; i < K; ++i) {\n",
        "            printf(\"Centroid %d: \", i);\n",
        "            for (int j = 0; j < num_dims; ++j) {\n",
        "                printf(\"%f \", h_centroids[i * num_dims + j]);\n",
        "            }\n",
        "            printf(\"\\n\");\n",
        "        }*/\n",
        "    }\n",
        "\n",
        "    cudaEventRecord(stop_total);\n",
        "    cudaEventSynchronize(stop_total);\n",
        "\n",
        "    float total_milliseconds = 0;\n",
        "    cudaEventElapsedTime(&total_milliseconds, start_total, stop_total);\n",
        "    printf(\"Total time: %f seconds\\n\", total_milliseconds / 1000.0);\n",
        "\n",
        "    cudaFree(d_datapoints);\n",
        "    cudaFree(d_clust_assn);\n",
        "    cudaFree(d_centroids);\n",
        "    cudaFree(d_clust_sizes);\n",
        "\n",
        "    cudaStreamDestroy(streams[0]);\n",
        "    cudaStreamDestroy(streams[1]);\n",
        "\n",
        "    free(h_centroids);\n",
        "    free(datapoints);\n",
        "    free(h_clust_sizes);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5yt8D0zOjJu",
        "outputId": "107884c9-a803-4fee-9d2b-6345d26cd49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0.000728 seconds\n"
          ]
        }
      ],
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_10000.csv 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_10000.csv 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGzS10rk0kff",
        "outputId": "857d4fbc-7366-408d-bc65-d31efe54413d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0.001503 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_10000.csv 1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AadLOBG00lOF",
        "outputId": "d4bba7dc-edd4-4273-a620-32ec07e6f7ee"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0.009231 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_100000.csv 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9TOpNu90mqN",
        "outputId": "5576a674-d887-4fdc-b207-7a670d0275ab"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0.001730 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_100000.csv 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xoJPm9D0plN",
        "outputId": "286f4379-453f-49a0-8ca8-bac9fe3e1be2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0.006322 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_100000.csv 1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1enDomKt0qeo",
        "outputId": "03931a50-6a2b-43f9-d476-7cbbdfb569f9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0.046692 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_1000000.csv 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HffUeXg50rT-",
        "outputId": "ba932e00-44ff-4cb8-97b9-c620b29505d2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0.010131 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_1000000.csv 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DysNmjwp0sgE",
        "outputId": "945986db-176f-46b1-c0f9-36cc4280c00e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0.055107 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_1000000.csv 1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXyNCtsh0uFG",
        "outputId": "22d3f98e-9918-43d7-d99e-64a0bda97044"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0.352530 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_10000000.csv 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHt-_Rt30vJK",
        "outputId": "8d634e87-76f3-4993-b157-f6ca06c30def"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0.094549 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_10000000.csv 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S4nYcWT0wvD",
        "outputId": "44f74f75-952d-4a7a-e55c-37d330b1cf73"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0.380678 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kmeans_rnd.cu -o kmeans_rnd\n",
        "!./kmeans_rnd random_data_10000000.csv 1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7UkQQ180y3Y",
        "outputId": "c91319bb-ac21-4751-9eeb-fff513d4fa44"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 2.180443 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}